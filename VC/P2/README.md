# ü§ñ Pr√°ctica 2 ü§ñ

## Descripci√≥n del trabajo
En esta pr√°ctica seguimos explorando el uso de OpenCV, centr√°ndonos en cuatro tareas:

- Cuenta de pixeles por filas
  
  ### üìè Tarea 1 üìè
  En la tarea 1 se trabaja con la imagen del mandril aplicando t√©cnicas de detecci√≥n de bordes y an√°lisis de filas. El flujo de procesamiento es el siguiente:

  - Se carga la imagen y se convierte a escala de grises con `cv2.cvtColor`.
  - Se aplica el detector de bordes de **Canny** (`cv2.Canny`) para resaltar los contornos principales de la imagen.
  - A partir de la imagen binaria resultante, se realiza una **cuenta de p√≠xeles blancos por fila**. Para ello:
    - Se usa `cv2.reduce` para obtener la suma de valores de cada fila.
    - Se normalizan los valores dividiendo entre 255, de manera que cada unidad corresponde a un p√≠xel blanco.
  - Se identifica la fila con el **m√°ximo n√∫mero de p√≠xeles blancos** mediante `np.argmax`.
  - Se calcula un umbral equivalente al **90% del valor m√°ximo**, y se seleccionan las filas que lo superan.
  - Finalmente, se generan representaciones gr√°ficas con **Matplotlib**:
    - En la primera figura se muestra la imagen binarizada con el detector de Canny.
    - En la segunda figura se presenta la **distribuci√≥n de p√≠xeles blancos por fila**, destacando:
      - El m√°ximo de p√≠xeles en color rojo.
      - El umbral del 90% en color naranja.
      - Las filas que superan dicho umbral marcadas en color verde.

  El resultado permite **visualizar y analizar qu√© filas concentran la mayor cantidad de p√≠xeles blancos**, lo que facilita comprender la distribuci√≥n de bordes detectados       en la imagen.


- Procesamiento y an√°lisis de im√°genes mediante umbralizado.

  ### üñºÔ∏è Tarea 2 üñºÔ∏è
  En la tarea 2 se trabaja con la conocida imagen del mandril. El flujo de procesamiento es el siguiente:

  - Se convierte la imagen a escala de grises con `cv2.cvtColor`.
  - Se suaviza con un filtro Gaussiano (`cv2.GaussianBlur`) para eliminar altas frecuencias.
  - Se aplica el operador Sobel en las direcciones **x** e **y** y se combinan los resultados (`cv2.add`).
  - Se convierte la imagen a 8 bits (`cv2.convertScaleAbs`) y se aplica un umbral binario con `cv2.threshold`.
  - Se realiza un conteo de p√≠xeles no nulos en cada fila y columna usando `np.count_nonzero`.
  - Se calculan los m√°ximos de filas y columnas, y se seleccionan aquellas que superan el **90%** del m√°ximo.
  - Finalmente, se remarcan dichas filas (en rojo) y columnas (en verde) sobre la imagen original con `cv2.line`.

  Con todos estos pasos se obtiene como resultado una imagen en la que se muestran las filas y columnas con mayor cantidad de p√≠xeles blancos.

- Demostraci√≥n de cambio de modo de procesamiento en Webcam.

  ### üì∑ Tarea 3 üì∑
  En la tarea 3 se propone crear un demostrador interactivo con la webcam, con varios modos de visualizaci√≥n:

  - **Modo 0 (Normal):** Muestra la c√°mara en tiempo real sin cambios.  
  - **Modo 1 (Inverso):** Aplica un negativo de la imagen (`cv2.bitwise_not`).  
  - **Modo 2 (Reducci√≥n de bits):** Se reduce la profundidad de color (cuantizaci√≥n) variando los bits por canal RGB.  

  üìå **Controles del demostrador**:
  - `m` ‚Üí Cambiar entre modos.  
  - `a` ‚Üí Reducir la cantidad de bits (m√≠nimo 1).  
  - `d` ‚Üí Aumentar la cantidad de bits (m√°ximo 8).  
  - `q` ‚Üí Salir del programa.  

  En el modo 1 se observa c√≥mo la imagen se convierte en tonalidad negativa y, en el modo 2, la imagen muestra en la esquina superior izquierda el n√∫mero de bits actuales. Esto permite apreciar c√≥mo cambia la cantidad de colores posibles gracias a los bits y c√≥mo la imagen se degrada visualmente al llegar hasta 1 bit como m√≠nimo.

- Creaci√≥n de un demostrador interactivo con la c√°mara.
  ### üéÆ Tarea 4 üéÆ
  En la tarea 4 se implementa un **demostrador interactivo de control musical mediante gestos de la mano**, combinando el uso de **MediaPipe** para el reconocimiento de gestos y **Pygame** para la reproducci√≥n de audio. El flujo de procesamiento es el siguiente:

  - Se inicializa el m√≥dulo `pygame.mixer` y se cargan varias pistas de audio (rock, reggae y surf).  
  - Se configura **MediaPipe Hands** con un umbral de confianza para la detecci√≥n y el seguimiento de la mano.  
  - Se captura v√≠deo en tiempo real desde la c√°mara (`cv2.VideoCapture`).  
  - Para cada frame:
    - Se procesa la imagen en formato RGB con MediaPipe para detectar la mano y extraer sus **landmarks**.  
    - Se dibujan los puntos y conexiones de la mano sobre la imagen.  
    - Se aplica la funci√≥n `detect_gesture`, que analiza la posici√≥n relativa de los dedos:
      - **Gesto rock** ‚Üí `[0,1,0,0,1]` (√≠ndice y me√±ique extendidos).  
      - **Gesto reggae** ‚Üí `[0,1,1,0,0]` (√≠ndice y medio en forma de ‚ÄúV‚Äù).  
      - **Gesto surf** ‚Üí `[1,0,0,0,1]` (pulgar y me√±ique extendidos).  
  - Seg√∫n el gesto detectado:
    - Si cambia respecto al anterior, se detiene la reproducci√≥n en curso.  
    - Si el gesto corresponde a uno v√°lido, se carga la canci√≥n asociada y se reproduce en bucle.  
  - El resultado es un **control musical manos libres**, donde el usuario puede alternar entre estilos musicales simplemente mostrando gestos espec√≠ficos frente a la c√°mara.

  Este demostrador pone en pr√°ctica la integraci√≥n de **visi√≥n por computador (MediaPipe)** con la **interactividad multimedia (Pygame)**, mostrando un ejemplo atractivo y creativo de interacci√≥n natural basada en gestos.


## Autor√≠a
Este trabajo ha sido realizado por:  

**Pablo Medina Quintana:** Tareas 1 y 4  
**Suliman Hassan:** Tareas 2 y 3

## Fuentes y referencias
Durante el desarrollo de la pr√°ctica se han consultado y utilizado las siguientes fuentes:  

- Documentaci√≥n oficial de [NumPy](https://numpy.org/doc/).  
- Documentaci√≥n oficial de [OpenCV](https://docs.opencv.org/).  
- Documentaci√≥n oficial de [MediaPipe](https://developers.google.com/mediapipe).  
- Documentaci√≥n oficial de [Pillow](https://pillow.readthedocs.io/).  
- Documentaci√≥n oficial de [Matplotlib](https://matplotlib.org/stable/contents.html).  
- Documentaci√≥n oficial de [Pygame](https://www.pygame.org/docs/).  

## Requisitos de instalaci√≥n
Para ejecutar el cuaderno correctamente es necesario tener instalado **Python 3.8 o superior** y las siguientes librer√≠as:  

```bash
pip install numpy opencv-python pillow matplotlib mediapipe pygame



