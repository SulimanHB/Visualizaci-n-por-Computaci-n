{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2fdbf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import joblib\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from torchvision import models, transforms\n",
    "from collections import deque\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a90eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Conteo por clase: {'angry': 705, 'disgust': 717, 'fear': 281, 'happy': 4772, 'sad': 1982, 'surprise': 1290, 'neutral': 2524}\n",
      "Mínimo encontrado = 281\n",
      "Máximo permitido por clase = 562\n",
      "Conteo por clase: {'angry': 162, 'disgust': 160, 'fear': 74, 'happy': 1185, 'sad': 478, 'surprise': 329, 'neutral': 680}\n",
      "Mínimo encontrado = 74\n",
      "Máximo permitido por clase = 148\n",
      "\n",
      "Entrenamiento de SVM\n",
      "\n",
      "Se guardo el modelo como emotion_svm_mobilenet.pkl\n",
      "\n",
      "Precisión registrada: 51.04%\n",
      "\n",
      "Reporte por clase:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.58      0.64      0.61       148\n",
      "     disgust       0.41      0.39      0.40       148\n",
      "        fear       0.70      0.47      0.56        74\n",
      "       happy       0.56      0.53      0.55       148\n",
      "         sad       0.39      0.39      0.39       148\n",
      "    surprise       0.61      0.67      0.64       148\n",
      "     neutral       0.43      0.47      0.45       148\n",
      "\n",
      "    accuracy                           0.51       962\n",
      "   macro avg       0.53      0.51      0.51       962\n",
      "weighted avg       0.51      0.51      0.51       962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH = \"data/train\"\n",
    "TEST_PATH  = \"data/test\"\n",
    "\n",
    "BALANCE_FACTOR = 2   # Aquí decides cuanto quieres multiplicar\n",
    "\n",
    "emotion_to_idx = {\n",
    "    \"angry\": 0,\n",
    "    \"disgust\": 1,\n",
    "    \"fear\": 2,\n",
    "    \"happy\": 3,\n",
    "    \"sad\": 4,\n",
    "    \"surprise\": 5,\n",
    "    \"neutral\": 6,\n",
    "}\n",
    "\n",
    "idx_to_emotion = {v: k for k, v in emotion_to_idx.items()}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "\n",
    "mobilenet = models.mobilenet_v2(\n",
    "    weights=\"MobileNet_V2_Weights.IMAGENET1K_V1\"\n",
    ").to(device)\n",
    "mobilenet.classifier = torch.nn.Identity()\n",
    "mobilenet.eval()\n",
    "\n",
    "transform_img = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "def extract_embedding(img):\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    pil_img = transforms.ToPILImage()(img_rgb)\n",
    "    tensor = transform_img(pil_img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        embedding = mobilenet(tensor).cpu().numpy().flatten()\n",
    "    return embedding\n",
    "\n",
    "\n",
    "def get_class_counts(base_path):\n",
    "    counts = {}\n",
    "    for emotion in emotion_to_idx.keys():\n",
    "        folder = os.path.join(base_path, emotion)\n",
    "        if os.path.isdir(folder):\n",
    "            counts[emotion] = len(os.listdir(folder))\n",
    "        else:\n",
    "            counts[emotion] = 0\n",
    "    return counts\n",
    "\n",
    "\n",
    "def load_dataset_balanced(base_path, factor=2):\n",
    "    counts = get_class_counts(base_path)\n",
    "    print(\"Conteo por clase:\", counts)\n",
    "\n",
    "    min_count = min(counts.values())\n",
    "    print(f\"Mínimo encontrado = {min_count}\")\n",
    "\n",
    "    max_per_class = min_count * factor\n",
    "    print(f\"Máximo permitido por clase = {max_per_class}\")\n",
    "\n",
    "    X, y = [], []\n",
    "\n",
    "    for emotion_name, label in emotion_to_idx.items():\n",
    "        folder = os.path.join(base_path, emotion_name)\n",
    "        if not os.path.isdir(folder):\n",
    "            print(\"Carpeta no encontrada:\", folder)\n",
    "            continue\n",
    "\n",
    "        files = os.listdir(folder)\n",
    "\n",
    "        use_n = min(len(files), max_per_class)\n",
    "\n",
    "        selected_files = np.random.choice(files, use_n, replace=False)\n",
    "\n",
    "\n",
    "        for img_name in selected_files:\n",
    "            img_path = os.path.join(folder, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            emb = extract_embedding(img)\n",
    "            X.append(emb)\n",
    "            y.append(label)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = load_dataset_balanced(TRAIN_PATH, BALANCE_FACTOR)\n",
    "\n",
    "X_test, y_test = load_dataset_balanced(TEST_PATH, BALANCE_FACTOR)\n",
    "\n",
    "print(\"\\nEntrenamiento de SVM\")\n",
    "\n",
    "clf = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVC(kernel=\"rbf\", C=15, gamma=\"scale\", probability=True)\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "joblib.dump(clf, \"emotion_svm_mobilenet.pkl\")\n",
    "print(\"\\nSe guardo el modelo como emotion_svm_mobilenet.pkl\")\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nPrecisión registrada: {acc*100:.2f}%\\n\")\n",
    "\n",
    "print(\"Reporte por clase:\")\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    target_names=[idx_to_emotion[i] for i in range(7)]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08752c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "YOLO_MODEL = \"yolov8n-face-lindevs.pt\"\n",
    "SVM_MODEL  = \"emotion_svm_mobilenet.pkl\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "yolo = YOLO(YOLO_MODEL)\n",
    "\n",
    "mobilenet = models.mobilenet_v2(\n",
    "    weights=\"MobileNet_V2_Weights.IMAGENET1K_V1\"\n",
    ").to(device)\n",
    "mobilenet.classifier = torch.nn.Identity()\n",
    "mobilenet.eval()\n",
    "\n",
    "transform_face = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "clf = joblib.load(SVM_MODEL)\n",
    "\n",
    "emotion_to_idx = {\n",
    "    \"angry\": 0, \"disgust\": 1, \"fear\": 2,\n",
    "    \"happy\": 3, \"sad\": 4, \"surprise\": 5,\n",
    "    \"neutral\": 6\n",
    "}\n",
    "idx_to_emotion = {v: k for k, v in emotion_to_idx.items()}\n",
    "\n",
    "emotion_colors = {\n",
    "    \"angry\": (0, 0, 255),\n",
    "    \"disgust\": (0, 128, 0),\n",
    "    \"fear\": (128, 0, 128),\n",
    "    \"happy\": (0, 255, 255),\n",
    "    \"sad\": (255, 128, 0),\n",
    "    \"surprise\": (255, 0, 255),\n",
    "    \"neutral\": (128, 128, 128)\n",
    "}\n",
    "\n",
    "\n",
    "history = deque(maxlen=20)\n",
    "\n",
    "def stable_emotion(history):\n",
    "    from collections import Counter\n",
    "    c = Counter(history)\n",
    "    emotion, count = c.most_common(1)[0]\n",
    "    if count / len(history) >= 0.40:\n",
    "        return emotion\n",
    "    return history[-1]\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = yolo(frame, verbose=False)\n",
    "    boxes = results[0].boxes.xyxy.cpu().numpy().astype(int)\n",
    "\n",
    "    emotion_now = \"neutral\"\n",
    "\n",
    "    for (x1, y1, x2, y2) in boxes:\n",
    "        w = x2 - x1\n",
    "        h = y2 - y1\n",
    "\n",
    "        fx1 = int(x1 + w * 0.15)\n",
    "        fy1 = int(y1 + h * 0.18)\n",
    "        fx2 = int(x2 - w * 0.15)\n",
    "        fy2 = int(y2 - h * 0.10)\n",
    "\n",
    "        face = frame[fy1:fy2, fx1:fx2]\n",
    "        if face.size == 0:\n",
    "            continue\n",
    "\n",
    "        rgb = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "        pil_img = transforms.ToPILImage()(rgb)\n",
    "        tensor = transform_face(pil_img).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            emb = mobilenet(tensor).cpu().numpy().flatten()\n",
    "\n",
    "        probs = clf.predict_proba([emb])[0]\n",
    "        pred_idx = np.argmax(probs)\n",
    "\n",
    "        if pred_idx == emotion_to_idx[\"happy\"] and probs[pred_idx] < 0.60:\n",
    "            pred_idx = np.argsort(probs)[-2]\n",
    "\n",
    "        emotion_now = idx_to_emotion[pred_idx]\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, emotion_now, (x1, y1 - 12),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "\n",
    "    # Suavizado\n",
    "    history.append(emotion_now)\n",
    "    emo = stable_emotion(history)\n",
    "\n",
    "    overlay = frame.copy()\n",
    "    color = emotion_colors[emo]\n",
    "    cv2.rectangle(overlay, (0, 0), (frame.shape[1], frame.shape[0]), color, -1)\n",
    "    frame = cv2.addWeighted(overlay, 0.25, frame, 0.75, 0)\n",
    "\n",
    "    cv2.putText(frame, emo, (20, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.4, (255, 255, 255), 3)\n",
    "\n",
    "    cv2.imshow(\"YOLO Face + MobileNet + SVM\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC-P5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
