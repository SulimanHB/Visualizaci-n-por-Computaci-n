# üí∞ Pr√°ctica 3 üí∞

## Descripci√≥n del trabajo
En esta pr√°ctica se desarrollan **dos tareas principales** orientadas al an√°lisis de im√°genes mediante t√©cnicas de visi√≥n por computador y aprendizaje autom√°tico, empleando **OpenCV**, **NumPy**, **scikit-image** y **scikit-learn**.  

Las tareas abordan dos problemas distintos:

1. **Estimaci√≥n autom√°tica de la cantidad de dinero presente en una imagen con monedas.**  
2. **Clasificaci√≥n de micropl√°sticos a partir de sus caracter√≠sticas geom√©tricas y visuales.**

---

## Tarea 1 ‚Äî Detecci√≥n y valoraci√≥n autom√°tica de monedas

Esta tarea tiene como objetivo **identificar y cuantificar monedas** presentes en una imagen, estimando la cantidad total de dinero.  

#### üß© Flujo de procesamiento
1. **Detecci√≥n de monedas:**  
   - Se utiliza el detector de c√≠rculos de **Hough (`cv2.HoughCircles`)** sobre una imagen suavizada en escala de grises.  
   - Se detectan las coordenadas y radios de las posibles monedas.  

2. **Selecci√≥n de referencia interactiva:**  
   - El usuario hace clic sobre una moneda conocida (por defecto, **1‚Ç¨**).  
   - Conociendo su di√°metro real (23.25 mm), se calcula el **factor de conversi√≥n de mil√≠metros por p√≠xel**, que servir√° para estimar el tama√±o de las dem√°s monedas.

3. **Clasificaci√≥n por color:**  
   - Se transforma la imagen al espacio **HSV** y se analiza la tonalidad y saturaci√≥n en el **centro y anillo** de cada moneda.  
   - Seg√∫n el color predominante, las monedas se agrupan en tres categor√≠as:
     - **Cobre:** monedas de 1, 2 y 5 c√©ntimos.  
     - **Oro:** monedas de 10, 20 y 50 c√©ntimos.  
     - **Bicolor:** monedas de 1‚Ç¨ y 2‚Ç¨.  

4. **Clasificaci√≥n por tama√±o:**  
   - A partir del valor de mil√≠metros por p√≠xel, se calcula el di√°metro real de cada moneda.  
   - Se compara este valor con los di√°metros oficiales para determinar el tipo de moneda m√°s probable.  

5. **C√°lculo del valor total y visualizaci√≥n:**  
   - Se suman los valores monetarios seg√∫n la clasificaci√≥n obtenida.  
   - Sobre la imagen se muestran:
     - El nombre de cada moneda.  
     - El contorno detectado.  
     - El **total estimado de dinero en euros.**  

#### üñºÔ∏è Resultados
El sistema permite procesar tanto la **imagen ideal proporcionada** como **fotograf√≠as reales capturadas por el usuario**.  
En casos reales, se pueden observar errores cuando:
- Existen **solapes entre monedas**.  
- Aparecen **reflejos intensos o variaciones de iluminaci√≥n**.  
- Hay **objetos no monetarios** con forma circular.  

A pesar de estas limitaciones, el m√©todo demuestra una **buena precisi√≥n** para im√°genes bien iluminadas y sin solapes significativos.  

#### üìã Ejemplo de flujo
```bash
Procesando Monedas.jpg ...
Referencia seleccionada: 1‚Ç¨ ‚Äî Escala = 0.1264 mm/pixel
üí∞ Total contado: 3.88 ‚Ç¨
```
<img width="328" height="681" alt="image" src="https://github.com/user-attachments/assets/1d68d9a1-c2a3-40b4-80ee-3f398ec81f14" />
<img width="327" height="678" alt="image" src="https://github.com/user-attachments/assets/594ae874-1ae6-47d3-891d-e24dbb11b214" />




#### ‚öôÔ∏è T√©cnicas y librer√≠as utilizadas
- `cv2.HoughCircles` ‚Äî detecci√≥n de c√≠rculos.  
- `cv2.cvtColor`, `cv2.mean`, `cv2.GaussianBlur` ‚Äî an√°lisis de color y suavizado.  
- `numpy` ‚Äî operaciones num√©ricas.  
- Interfaz interactiva mediante **eventos de rat√≥n en OpenCV**.  

---

## Tarea 2 ‚Äî Clasificaci√≥n autom√°tica de micropl√°sticos

En esta tarea se implementa un sistema de **an√°lisis de part√≠culas** con el fin de identificar el tipo de micropl√°stico presente en distintas im√°genes.  

#### üß† Objetivo
A partir de tres conjuntos de entrenamiento (fragmentos negros, pellets esf√©ricos y films transl√∫cidos), el sistema **aprende patrones de forma, color y textura** para clasificar nuevas muestras de prueba (*MPs_test.jpg*).  

### **üìÅ Datos de entrada**

Im√°genes de entrenamiento (una por clase, con m√∫ltiples instancias):


- TAR.png ‚Üí fragmentos_negros  
  <img src="TAR.png" alt="fragmentos_negros" width="150"><br>

- PEL.png ‚Üí pellets_esfericos  
  <img src="PEL.png" alt="fragmentos_negros" width="150"><br>

- FRA.png ‚Üí films_translucidos  
  <img src="FRA.png" alt="films_translucidos" width="150"><br>

- Imagen de test: MPs_test.jpg  
  <img src="MPs_test.jpg" alt="test" width="150"><br>

- Anotaciones de test: MPs_test_bbs.csv con columnas:

- x_min, y_min, x_max, y_max (int, p√≠xeles)

- label en {TAR, PEL, FRA} (se mapea a las clases finales)


## **üîÑ Flujo de procesamiento**

### **Preprocesado / Segmentaci√≥n**
- Conversi√≥n a grises y Gaussian Blur(**`cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)`** y **`cv2.GaussianBlur(gray, (5, 5), 0)`**).
- Otsu binario inverso + adaptativo(**`cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)`**).
- Fusi√≥n (OR) para conservar detalle en zonas poco contrastadas.
- Morfolog√≠a con remove_small_objects para limpiar y rellenar.
- Salida: m√°scara binaria.


### **Aplicaci√≥n de presprocesado**

- TAR presprocesada 
  <img src="TAR-PRES.png" alt="fragmentos_negros" width="750"><br>

- PEL presprocesada   
  <img src="PEL-PRES.png" alt="fragmentos_negros" width="750"><br>

- FRA presprocesada  
  <img src="FRA-PRES.png" alt="films_translucidos" width="750"><br>


### **Extracci√≥n de caracter√≠sticas**


- Etiquetado de componentes y regionprops.

- Se descartan los objetos con area < 100.

- Para cada objeto se calculan estos aspectos:
  - *Geometr√≠a*: `area`, `circularity`, `aspect`, `extent`, `solidity`.

  - *Color HSV*: `h_mean`, `s_mean`, `v_mean`, `h_std`, `s_std`, `v_std`.

  - *Textura*: `var_intensity`, `contrast`.


### **Preparaci√≥n de datos**
- Entrenamiento (prepare_training()):

  - Para cada imagen de TRAIN: segmenta ‚Üí extrae features ‚Üí acumula todas las filas y sus etiquetas.

  - Balanceo por downsampling: se iguala el n¬∫ de muestras por clase al m√≠nimo encontrado (resample(..., n_samples=min_n)).

  - Devuelve X, Y balanceados.

- Test (prepare_test()):

  - Lee MPs_test_bbs.csv y mapea label ‚Üí `gt_class`.

  - Por cada bbox: recorta ‚Üí `segmenta` ‚Üí extrae features; si no hay objetos, usa un vector nulo (1√ó13).

  - Promedia las features por bbox ‚Üí una fila por regi√≥n.

  - Devuelve `X_test`, `y_true`, `df`.


### **Ejecuci√≥n**

- Entrena un RandomForestClassifier con `X_train, y_train de prepare_training()` (ya balanceados).

- Eval√∫a con `prepare_test()` ‚Üí obtiene `X_test`, `y_true` y **predice**.

- Reajuste simple por brillo (`V de HSV`):

  - si v_mean < 85 ‚Üí fragmentos_negros

  - si v_mean > 155 y era fragmentos_negros ‚Üí films_translucidos

- # Resultado  
  <img src="Resultado-final.png" alt="films_translucidos" width="750"><br>

Podemos observar que el resultado es bastante preciso siendo de un `74,2%`, siendo muy favorable y mostrando que el codigo acierta 3/4 part√≠culas.

Guardando un csv con las predicciones resueltas.


#### üß© T√©cnicas empleadas
- **Segmentaci√≥n h√≠brida:** Otsu + umbral adaptativo.  
- **Extracci√≥n de caracter√≠sticas:** `regionprops`, HSV y estad√≠sticos de textura.  
- **Clasificaci√≥n:** `RandomForestClassifier`.  
- **Evaluaci√≥n:** `confusion_matrix`, `classification_report`, `seaborn.heatmap`.  

#### üß™ Observaciones
El sistema muestra **alta precisi√≥n** incluso con iluminaci√≥n variable. Sin embargo, puede verse afectado por:
- Part√≠culas con **bordes irregulares o parcialmente segmentadas**.  
- Zonas con **transparencias o reflexiones** dif√≠ciles de umbralizar.  
- Desequilibrio inicial en el n√∫mero de muestras por clase (compensado con resampling).  

---

## üë• Autor√≠a
Este trabajo ha sido realizado por:

**Pablo Medina Quintana** ‚Äî Tarea 1<br>
**Suliman Hassan El Boutaybi** ‚Äî Tarea 2
---

## üìö Fuentes y referencias
Durante el desarrollo de la pr√°ctica se han consultado las siguientes fuentes:

- Documentaci√≥n oficial de [OpenCV](https://docs.opencv.org/).  
- Documentaci√≥n de [NumPy](https://numpy.org/doc/).  
- Documentaci√≥n de [scikit-image](https://scikit-image.org/docs/stable/).  
- Documentaci√≥n de [scikit-learn](https://scikit-learn.org/stable/).  
- Publicaci√≥n original del trabajo [SMACC: A System for Microplastics Automatic Counting and Classification](https://doi.org/10.1109/ACCESS.2020.2970498).  
- Documentaci√≥n de [Matplotlib](https://matplotlib.org/).  
- Documentaci√≥n de [Seaborn](https://seaborn.pydata.org/).  

---

## üß∞ Requisitos de instalaci√≥n
Para ejecutar correctamente las tareas se requiere **Python 3.8 o superior** y las siguientes librer√≠as:

```bash
pip install numpy opencv-python scikit-image scikit-learn pandas matplotlib seaborn
```
